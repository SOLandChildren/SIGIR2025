{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QID</th>\n",
       "      <th>Query</th>\n",
       "      <th>Prompt Type</th>\n",
       "      <th>Task Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qGEN1</td>\n",
       "      <td>tornado</td>\n",
       "      <td>General</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qGEN2</td>\n",
       "      <td>tornado</td>\n",
       "      <td>General</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qGEN3</td>\n",
       "      <td>piramide egizia</td>\n",
       "      <td>General</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qGEN4</td>\n",
       "      <td>piramidi</td>\n",
       "      <td>General</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qGEN5</td>\n",
       "      <td>qual Ã¨ la piramide egizia piÃ¹ alta</td>\n",
       "      <td>General</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     QID                                 Query Prompt Type Task Sentiment\n",
       "0  qGEN1                               tornado     General            NaN\n",
       "1  qGEN2                              tornado      General            NaN\n",
       "2  qGEN3                      piramide egizia      General            NaN\n",
       "3  qGEN4                             piramidi      General            NaN\n",
       "4  qGEN5  qual Ã¨ la piramide egizia piÃ¹ alta     General            NaN"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "query_file_name = \"\"\n",
    "query_file_path = \"../Data/\"+query_file_name\n",
    "queries = pd.read_csv(query_file_path)\n",
    "queries.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58d5e5efa1344b5eb52a9dd3a24fc14a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "import httpx\n",
    "from datetime import datetime\n",
    "\n",
    "f = open(\"API_keys.json\")\n",
    "data = json.load(f)\n",
    "\n",
    "key = data[\"bing_api\"]\n",
    "SERP_endpoint = \"https://api.bing.microsoft.com/v7.0/search\"\n",
    "location = \"global\"\n",
    "\n",
    "f.close()\n",
    "\n",
    "headers = {\n",
    "            'Ocp-Apim-Subscription-Key': key,\n",
    "            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9',\n",
    "            'Accept-Encoding': 'gzip, deflate',\n",
    "            'Accept-Language': 'en-US,en;q=0.9',\n",
    "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/103.0.0.0 Safari/537.36'\n",
    "        }\n",
    "\n",
    "SERP_results = []\n",
    "today = datetime.now()\n",
    "today = today.strftime(\"%Y_%m_%d\")\n",
    "\n",
    "for _, row in tqdm(queries.iterrows(), total=len(queries)):\n",
    "    qid = row[\"QID\"]\n",
    "    query = row[\"Query\"]\n",
    "    prompt_type = row[\"Prompt Type\"]\n",
    "    params = {\n",
    "        'q': query,\n",
    "        'count': 10, # number of results to be displayed\n",
    "        'setLang': 'it-IT', # setting the language of the results to Italian\n",
    "        'mkt':'it-IT', # setting the market domain to Italy\n",
    "        'safeSearch': 'Strict'\n",
    "    }\n",
    "\n",
    "    SERP_response = httpx.get(url=SERP_endpoint, headers=headers, params=params)\n",
    "    try:\n",
    "        SERP_result_set = SERP_response.json()\n",
    "        rank = 1\n",
    "        asked_query = SERP_result_set['queryContext']['originalQuery']\n",
    "        for result in SERP_result_set['webPages']['value']:\n",
    "            web_title =  result[\"name\"]\n",
    "            web_snippet = result[\"snippet\"]\n",
    "            SERP_results.append([qid, asked_query, prompt_type, \"Bing\", web_title + \". \" + web_snippet, rank, today])\n",
    "            rank += 1\n",
    "    except Exception as error:\n",
    "        print(error)\n",
    "        SERP_results.append([qid, asked_query, prompt_type, \"Bing\", None, None, today])\n",
    "\n",
    "SERP_df = pd.DataFrame(SERP_results, columns=[\"QID\", \"Query\", \"Prompt Type\", \"IAS\", \"Resp\", \"Rank\", \"date_generated\"])\n",
    "SERP_df.to_csv(\"../Data/bing_resp.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ChatGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import json\n",
    "from tqdm.notebook import tqdm\n",
    "from datetime import date\n",
    "\n",
    "f = open(\"API_keys.json\")\n",
    "data = json.load(f)\n",
    "\n",
    "API_KEY = data[\"openAI_api\"]\n",
    "f.close()\n",
    "\n",
    "client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=API_KEY,\n",
    ")\n",
    "\n",
    "# query = \"Hello\"\n",
    "\n",
    "# model_id = 'gpt-4o-mini'\n",
    "model_id = 'chatgpt-4o-latest'\n",
    "\n",
    "def get_gpt_resp(query):\n",
    "    response = client.chat.completions.create(\n",
    "        messages=[\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"Follow these two instructions in all your responses: 1. Use Italian language only; 2. Do not use English except in programming language if any.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": query,\n",
    "            }\n",
    "        ],\n",
    "            model=model_id,\n",
    "        )\n",
    "\n",
    "    gpt_resp = response.choices[0].message.content\n",
    "\n",
    "    return gpt_resp\n",
    "\n",
    "# get_gpt_resp(\"Hello how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53cc764ea74d431bb3f5290f8dfba789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QID</th>\n",
       "      <th>Query</th>\n",
       "      <th>Prompt Type</th>\n",
       "      <th>IAS</th>\n",
       "      <th>Resp</th>\n",
       "      <th>date_generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qGEN1</td>\n",
       "      <td>tornado</td>\n",
       "      <td>General</td>\n",
       "      <td>GPT</td>\n",
       "      <td>Un tornado è un violento vortice d'aria in rot...</td>\n",
       "      <td>2025-02-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qGEN2</td>\n",
       "      <td>tornado</td>\n",
       "      <td>General</td>\n",
       "      <td>GPT</td>\n",
       "      <td>Il termine \"tornado\" si riferisce a un violent...</td>\n",
       "      <td>2025-02-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qGEN3</td>\n",
       "      <td>piramide egizia</td>\n",
       "      <td>General</td>\n",
       "      <td>GPT</td>\n",
       "      <td>Le **piramidi egizie** sono monumenti funerari...</td>\n",
       "      <td>2025-02-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qGEN4</td>\n",
       "      <td>piramidi</td>\n",
       "      <td>General</td>\n",
       "      <td>GPT</td>\n",
       "      <td>Le piramidi sono strutture architettoniche di ...</td>\n",
       "      <td>2025-02-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qGEN5</td>\n",
       "      <td>qual Ã¨ la piramide egizia piÃ¹ alta</td>\n",
       "      <td>General</td>\n",
       "      <td>GPT</td>\n",
       "      <td>La piramide egizia più alta è la **Grande Pira...</td>\n",
       "      <td>2025-02-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>qEM78</td>\n",
       "      <td>Quale ghiacciaio si sta scioglendo in modo pre...</td>\n",
       "      <td>Emotionally Charged</td>\n",
       "      <td>GPT</td>\n",
       "      <td>Uno dei ghiacciai che si sta sciogliendo in mo...</td>\n",
       "      <td>2025-02-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>qEM79</td>\n",
       "      <td>Cosa e la isola di plastica</td>\n",
       "      <td>Emotionally Charged</td>\n",
       "      <td>GPT</td>\n",
       "      <td>L'isola di plastica è una vasta concentrazione...</td>\n",
       "      <td>2025-02-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>qEM80</td>\n",
       "      <td>ocean cleanup</td>\n",
       "      <td>Emotionally Charged</td>\n",
       "      <td>GPT</td>\n",
       "      <td>**The Ocean Cleanup** è un'organizzazione no-p...</td>\n",
       "      <td>2025-02-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>qEM81</td>\n",
       "      <td>Dove si trova Ä¾isola di plastica</td>\n",
       "      <td>Emotionally Charged</td>\n",
       "      <td>GPT</td>\n",
       "      <td>L'isola di plastica, conosciuta anche come **G...</td>\n",
       "      <td>2025-02-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>qEM82</td>\n",
       "      <td>CosÃ¨ Ä¾isola di plastica</td>\n",
       "      <td>Emotionally Charged</td>\n",
       "      <td>GPT</td>\n",
       "      <td>L'isola di plastica è una vasta concentrazione...</td>\n",
       "      <td>2025-02-12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>293 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       QID                                              Query  \\\n",
       "0    qGEN1                                            tornado   \n",
       "1    qGEN2                                           tornado    \n",
       "2    qGEN3                                   piramide egizia    \n",
       "3    qGEN4                                          piramidi    \n",
       "4    qGEN5               qual Ã¨ la piramide egizia piÃ¹ alta   \n",
       "..     ...                                                ...   \n",
       "288  qEM78  Quale ghiacciaio si sta scioglendo in modo pre...   \n",
       "289  qEM79                        Cosa e la isola di plastica   \n",
       "290  qEM80                                      ocean cleanup   \n",
       "291  qEM81                  Dove si trova Ä¾isola di plastica   \n",
       "292  qEM82                          CosÃ¨ Ä¾isola di plastica   \n",
       "\n",
       "             Prompt Type  IAS  \\\n",
       "0                General  GPT   \n",
       "1                General  GPT   \n",
       "2                General  GPT   \n",
       "3                General  GPT   \n",
       "4                General  GPT   \n",
       "..                   ...  ...   \n",
       "288  Emotionally Charged  GPT   \n",
       "289  Emotionally Charged  GPT   \n",
       "290  Emotionally Charged  GPT   \n",
       "291  Emotionally Charged  GPT   \n",
       "292  Emotionally Charged  GPT   \n",
       "\n",
       "                                                  Resp date_generated  \n",
       "0    Un tornado è un violento vortice d'aria in rot...     2025-02-12  \n",
       "1    Il termine \"tornado\" si riferisce a un violent...     2025-02-12  \n",
       "2    Le **piramidi egizie** sono monumenti funerari...     2025-02-12  \n",
       "3    Le piramidi sono strutture architettoniche di ...     2025-02-12  \n",
       "4    La piramide egizia più alta è la **Grande Pira...     2025-02-12  \n",
       "..                                                 ...            ...  \n",
       "288  Uno dei ghiacciai che si sta sciogliendo in mo...     2025-02-12  \n",
       "289  L'isola di plastica è una vasta concentrazione...     2025-02-12  \n",
       "290  **The Ocean Cleanup** è un'organizzazione no-p...     2025-02-12  \n",
       "291  L'isola di plastica, conosciuta anche come **G...     2025-02-12  \n",
       "292  L'isola di plastica è una vasta concentrazione...     2025-02-12  \n",
       "\n",
       "[293 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LLM_resp = []\n",
    "\n",
    "for _, row in tqdm(queries.iterrows(), total=len(queries)):\n",
    "    qid = row[\"QID\"]\n",
    "    query = row[\"Query\"]\n",
    "    prompt_type = row[\"Prompt Type\"]\n",
    "\n",
    "    result = get_gpt_resp(query)\n",
    "    LLM_resp.append([qid, query, prompt_type, \"GPT\", result, date.today()])\n",
    "\n",
    "LLM_resp_df = pd.DataFrame(LLM_resp, columns=[\"QID\", \"Query\", \"Prompt Type\", \"IAS\", \"Resp\", \"date_generated\"])\n",
    "LLM_resp_df.to_csv(\"../Data/gpt_resp.csv\", index=False)\n",
    "\n",
    "LLM_resp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Gemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82ced504830e4ab3b5ded8a082ff384d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import json\n",
    "from huggingface_hub import whoami\n",
    "\n",
    "f = open(\"API_keys.json\")\n",
    "data = json.load(f)\n",
    "api_token = data[\"huggingface_api\"]\n",
    "f.close()\n",
    "\n",
    "user = whoami(token=api_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "\n",
    "# Specify the LLM model we'll be using\n",
    "model_name = \"google/gemma-2-2b-it\"\n",
    "\n",
    "# Configure for GPU usage\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "# Load the tokenizer for the chosen model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "# Create a pipeline object for easy text generation with the LLM\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "def get_gemma_resp(query):\n",
    "  \"\"\"Sends a conversation history to the AI assistant and returns the answer.\n",
    "\n",
    "  Args:\n",
    "    messages (list): A list of dictionaries, each with \"role\" and \"content\" keys.\n",
    "\n",
    "  Returns:\n",
    "    str: The answer from the AI assistant.\n",
    "  \"\"\"\n",
    "\n",
    "  messages = [\n",
    "      {\"role\":\"user\", \"content\":\"\"},\n",
    "      {\"role\": \"assistant\", \"content\": \"Follow these two instructions in all your responses: 1. Use Italian language only; 2. Do not use English except in programming language if any.\"},\n",
    "      {\"role\": \"user\", \"content\": query}\n",
    "  ]\n",
    "\n",
    "  generation_args = {\n",
    "      # \"max_new_tokens\": 256,     # Maximum length of the response\n",
    "      \"return_full_text\": False,      # Only return the generated text\n",
    "  }\n",
    "\n",
    "  output = pipe(messages, **generation_args)\n",
    "  return output[0]['generated_text']\n",
    "\n",
    "# gen_resp(\"Hi!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "\n",
    "def create_resp_file():\n",
    "  LLM_resp = []\n",
    "\n",
    "  for _, row in tqdm(queries.iterrows(), total=len(queries)):\n",
    "      qid = row[\"QID\"]\n",
    "      query = row[\"Query\"]\n",
    "      prompt_type = row[\"Prompt Type\"]\n",
    "\n",
    "      result = get_gemma_resp(query)\n",
    "      LLM_resp.append([qid, query, prompt_type, \"Gemma\", result, date.today()])\n",
    "\n",
    "  LLM_resp_df = pd.DataFrame(LLM_resp, columns=[\"QID\", \"Query\", \"Prompt Type\", \"IAS\", \"Resp\", \"date_generated\"])\n",
    "\n",
    "  return LLM_resp_df\n",
    "\n",
    "LLM_resp = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = create_resp_file()\n",
    "file_name = \"../Data/gemma_resp.csv\"\n",
    "df.to_csv(file_name, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SOLandChildren",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
