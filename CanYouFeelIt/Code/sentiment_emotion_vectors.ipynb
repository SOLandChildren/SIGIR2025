{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing sentiment and emotion vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Language Model based approach: FEEL-IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>sent_sum</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>anger</th>\n",
       "      <th>fear</th>\n",
       "      <th>emo_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sono felice</td>\n",
       "      <td>sono felice</td>\n",
       "      <td>99.972600</td>\n",
       "      <td>0.027401</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.901080</td>\n",
       "      <td>0.041839</td>\n",
       "      <td>0.017075</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La deforestazione è un male</td>\n",
       "      <td>La deforestazione è un male</td>\n",
       "      <td>0.021573</td>\n",
       "      <td>99.978429</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.020934</td>\n",
       "      <td>92.929745</td>\n",
       "      <td>6.870100</td>\n",
       "      <td>0.179221</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Questo è spaventoso</td>\n",
       "      <td>Questo è spaventoso</td>\n",
       "      <td>0.021750</td>\n",
       "      <td>99.978250</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.100756</td>\n",
       "      <td>0.102739</td>\n",
       "      <td>0.093424</td>\n",
       "      <td>99.703085</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Questa è una mela marcia</td>\n",
       "      <td>Questa è una mela marcia</td>\n",
       "      <td>0.021880</td>\n",
       "      <td>99.978119</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.043510</td>\n",
       "      <td>70.565057</td>\n",
       "      <td>29.188761</td>\n",
       "      <td>0.202673</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mostro nero?</td>\n",
       "      <td>mostro nero?</td>\n",
       "      <td>0.023057</td>\n",
       "      <td>99.976939</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.033823</td>\n",
       "      <td>3.354726</td>\n",
       "      <td>94.834226</td>\n",
       "      <td>1.777218</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>lei è una bellezza terribile</td>\n",
       "      <td>lei è una bellezza terribile</td>\n",
       "      <td>0.022565</td>\n",
       "      <td>99.977440</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.864703</td>\n",
       "      <td>0.107148</td>\n",
       "      <td>0.014439</td>\n",
       "      <td>0.013711</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>L'Cleanup Ocean Ã¨ un movimento internazionale...</td>\n",
       "      <td>L'Cleanup Ocean Ã un movimento internazionale ...</td>\n",
       "      <td>73.182040</td>\n",
       "      <td>26.817957</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.575568</td>\n",
       "      <td>48.435834</td>\n",
       "      <td>0.285596</td>\n",
       "      <td>32.703006</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>La (tigre) \\n\\n    bianca Ã¨ una rara variante...</td>\n",
       "      <td>La tigre. bianca Ã una rara variante genetica ...</td>\n",
       "      <td>99.962687</td>\n",
       "      <td>0.037313</td>\n",
       "      <td>1.0</td>\n",
       "      <td>99.923551</td>\n",
       "      <td>0.029315</td>\n",
       "      <td>0.010889</td>\n",
       "      <td>0.036246</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0                                        sono felice   \n",
       "1                        La deforestazione è un male   \n",
       "2                                Questo è spaventoso   \n",
       "3                           Questa è una mela marcia   \n",
       "4                                       mostro nero?   \n",
       "5                       lei è una bellezza terribile   \n",
       "6  L'Cleanup Ocean Ã¨ un movimento internazionale...   \n",
       "7  La (tigre) \\n\\n    bianca Ã¨ una rara variante...   \n",
       "\n",
       "                                        cleaned_text   positive   negative  \\\n",
       "0                                        sono felice  99.972600   0.027401   \n",
       "1                        La deforestazione è un male   0.021573  99.978429   \n",
       "2                                Questo è spaventoso   0.021750  99.978250   \n",
       "3                           Questa è una mela marcia   0.021880  99.978119   \n",
       "4                                       mostro nero?   0.023057  99.976939   \n",
       "5                       lei è una bellezza terribile   0.022565  99.977440   \n",
       "6  L'Cleanup Ocean Ã un movimento internazionale ...  73.182040  26.817957   \n",
       "7  La tigre. bianca Ã una rara variante genetica ...  99.962687   0.037313   \n",
       "\n",
       "   sent_sum        joy    sadness      anger       fear  emo_sum  \n",
       "0       1.0  99.901080   0.041839   0.017075   0.040000      1.0  \n",
       "1       1.0   0.020934  92.929745   6.870100   0.179221      1.0  \n",
       "2       1.0   0.100756   0.102739   0.093424  99.703085      1.0  \n",
       "3       1.0   0.043510  70.565057  29.188761   0.202673      1.0  \n",
       "4       1.0   0.033823   3.354726  94.834226   1.777218      1.0  \n",
       "5       1.0  99.864703   0.107148   0.014439   0.013711      1.0  \n",
       "6       1.0  18.575568  48.435834   0.285596  32.703006      1.0  \n",
       "7       1.0  99.923551   0.029315   0.010889   0.036246      1.0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# santiy check\n",
    "\n",
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "emo_classifier = pipeline(\"text-classification\",model='MilaNLProc/feel-it-italian-emotion',top_k=4)\n",
    "sent_classifier = pipeline(\"text-classification\",model='MilaNLProc/feel-it-italian-sentiment',top_k=2)\n",
    "\n",
    "text_examples = [\n",
    "    \"sono felice\",\n",
    "    \"La deforestazione è un male\",\n",
    "    \"Questo è spaventoso\",\n",
    "    \"Questa è una mela marcia\",\n",
    "    \"mostro nero?\",\n",
    "    \"lei è una bellezza terribile\",\n",
    "    \"L'Cleanup Ocean Ã¨ un movimento internazionale che si Ã¨ formato per combattere la pollution del mare.\",\n",
    "    \"\"\"La (tigre) \n",
    "\n",
    "    bianca Ã¨ una rara variante genetica della tigre reale (Panthera tigris), \n",
    "    \n",
    "    caratterizzata da una particolare colorazione del mantello causata da una mutazione genetica. Questi bellissimi felini sono spesso oggetto di ammirazione e curiositÃ  per la loro singolare bellezza. Vive principalmente in India e in alcune parti del sud-est asiatico.\"\"\"\n",
    "]\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(\"(\\s?\\n){1,}\", \".\", text) # remove new lines and replace with .\n",
    "    text = re.sub(\"\\t{1,}\", \" \", text) # remove tab spaces and replace with a singular space\n",
    "    text = re.sub(\"[^\\w\\-(\\.{1})'\\!\\?]\", \" \", text) # remove non-alphanumeric symbols, except for ., ', !, -\n",
    "    text = re.sub(\"[\\(\\)\\[\\]\\{\\}]\", \"\", text) # remove brackets of any kind\n",
    "    text = re.sub(\"\\s{2,}\", \" \", text) # remove any multiple white spaces\n",
    "    text = text.strip() # remove any leading or ending white spaces\n",
    "    return text\n",
    "\n",
    "cleaned_text_examples = [clean_text(text) for text in text_examples]\n",
    "\n",
    "emo_scores = emo_classifier(cleaned_text_examples)\n",
    "sent_scores = sent_classifier(cleaned_text_examples)\n",
    "\n",
    "EP_semantic_results = {\n",
    "    \"text\": [],\n",
    "    \"cleaned_text\": [],\n",
    "    \"positive\": [],\n",
    "    \"negative\": [],\n",
    "    \"sent_sum\": [],\n",
    "    \"joy\": [],\n",
    "    \"sadness\": [],\n",
    "    \"anger\": [],\n",
    "    \"fear\": [],\n",
    "    \"emo_sum\": []\n",
    "}\n",
    "# print(emo_scores)\n",
    "\n",
    "\n",
    "for text, cleaned_text, sent_score, emo_score in zip(text_examples, cleaned_text_examples, sent_scores, emo_scores):\n",
    "    EP_semantic_results[\"text\"].append(text)\n",
    "    EP_semantic_results[\"cleaned_text\"].append(cleaned_text)\n",
    "    sent_sum = 0\n",
    "    emo_sum = 0\n",
    "    for sent_dict in sent_score:\n",
    "        EP_semantic_results[sent_dict[\"label\"]].append(sent_dict[\"score\"]*100)\n",
    "        sent_sum += sent_dict[\"score\"]\n",
    "    EP_semantic_results[\"sent_sum\"].append(sent_sum)\n",
    "    for emo_dict in emo_score:\n",
    "        EP_semantic_results[emo_dict[\"label\"]].append(emo_dict[\"score\"]*100)\n",
    "        emo_sum += emo_dict[\"score\"]\n",
    "    EP_semantic_results[\"emo_sum\"].append(emo_sum)\n",
    "\n",
    "# print(EP_semantic_results)\n",
    "df = pd.DataFrame.from_dict(EP_semantic_results)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import re\n",
    "\n",
    "tokenizer_kwargs = {'padding':True,'truncation':True,'max_length':512}\n",
    "emo_classifier = pipeline(\"text-classification\",model='MilaNLProc/feel-it-italian-emotion',top_k=4)\n",
    "sent_classifier = pipeline(\"text-classification\",model='MilaNLProc/feel-it-italian-sentiment',top_k=2)\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(\"(\\s?\\n){1,}\", \".\", text) # remove new lines and replace with .\n",
    "    text = re.sub(\"\\t{1,}\", \" \", text) # remove tab spaces and replace with a singular space\n",
    "    text = re.sub(\"[^\\w\\-(\\.{1})'\\!\\?]\", \" \", text) # remove non-alphanumeric symbols, except for ., ', !, -\n",
    "    text = re.sub(\"[\\(\\)\\[\\]\\{\\}]\", \"\", text) # remove brackets of any kind\n",
    "    text = re.sub(\"\\s{2,}\", \" \", text) # remove any multiple white spaces\n",
    "    text = text.strip() # remove any leading or ending white spaces\n",
    "    return text\n",
    "\n",
    "def get_sent_emo_vectors(texts, text_name):\n",
    "    cleaned_texts = [clean_text(text) for text in texts]\n",
    "    cleaned_text_name = text_name+\"_cleaned\"\n",
    "    try:\n",
    "        emo_scores = emo_classifier(cleaned_texts)\n",
    "        sent_scores = sent_classifier(cleaned_texts)\n",
    "    except:\n",
    "        emo_scores = emo_classifier(cleaned_texts, **tokenizer_kwargs)\n",
    "        sent_scores = sent_classifier(cleaned_texts, **tokenizer_kwargs)\n",
    "\n",
    "    EP_semantic_results = {\n",
    "        cleaned_text_name: [],\n",
    "        \"positive\": [],\n",
    "        \"negative\": [],\n",
    "        \"joy\": [],\n",
    "        \"sadness\": [],\n",
    "        \"anger\": [],\n",
    "        \"fear\": [],\n",
    "    }\n",
    "\n",
    "    for cleaned_text, sent_score, emo_score in tqdm(zip(cleaned_texts, sent_scores, emo_scores), total=len(cleaned_texts)):\n",
    "        EP_semantic_results[cleaned_text_name].append(cleaned_text)\n",
    "        for sent_dict in sent_score:\n",
    "            EP_semantic_results[sent_dict[\"label\"]].append(sent_dict[\"score\"]*100)\n",
    "        for emo_dict in emo_score:\n",
    "            EP_semantic_results[emo_dict[\"label\"]].append(emo_dict[\"score\"]*100)\n",
    "    df = pd.DataFrame.from_dict(EP_semantic_results)\n",
    "    return cleaned_text_name, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating sentiment and emotion vectors for file: gemma_resp_baseline\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2ef30343ff443a89a916b0826ab0ae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating sentiment and emotion vectors for file: gemma_resp_user_group_aware\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e67d2c5fe6af4ac4a12c6b03f54e1fe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating sentiment and emotion vectors for file: gemma_resp_user_need_aware\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a5804eb6b624bd6bcbabd53ff3d9b67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating sentiment and emotion vectors for file: gpt_resp_baseline\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15fc03be078f4889a6c1780975970ce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating sentiment and emotion vectors for file: gpt_resp_user_group_aware\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29c3837238884529a7efe1b9ff8bd529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/293 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating sentiment and emotion vectors for file: gpt_resp_user_need_aware\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c59ea9ced26a4ffdbd21a1cc64e5b1c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os  # import os module\n",
    "\n",
    "directory = '../Data/Responses/'  # set directory path\n",
    "\n",
    "for entry in os.scandir(directory):  \n",
    "    if entry.is_file():  # check if it's a file\n",
    "        resp_df = pd.read_csv(entry.path)\n",
    "        file_name = entry.name[:-4]     \n",
    "        print(\"\\nCreating sentiment and emotion vectors for file: \"+file_name)\n",
    "        \n",
    "        col_name, results_df = get_sent_emo_vectors(resp_df[\"Resp\"].tolist(), \"Resp\")\n",
    "        results_df[\"QID\"] = resp_df[\"QID\"]\n",
    "        results_df[\"Task Sentiment\"] = resp_df[\"Task Sentiment\"]\n",
    "        results_df[\"Task Sentiment\"] = results_df[\"Task Sentiment\"].fillna(value=\"General\")\n",
    "        \n",
    "        if \"gemma\" in file_name:\n",
    "            results_df[\"IAS\"] = [\"GEM\"]*len(resp_df)\n",
    "        elif \"gpt\" in file_name:\n",
    "            results_df[\"IAS\"] = [\"GPT\"]*len(resp_df)\n",
    "        \n",
    "        results_df = results_df.loc[:, [\"QID\", \"Task Sentiment\", \"IAS\", col_name, \"positive\", \"negative\", \"joy\", \"sadness\", \"anger\", \"fear\"]]\n",
    "        \n",
    "        \n",
    "        file_path = \"../Results/QueryWise_\"+file_name+\".csv\"\n",
    "        results_df.to_csv(file_path, index=False)\n",
    "        # results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Emotional Profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IAS</th>\n",
       "      <th>Prompt Type</th>\n",
       "      <th>Task Sentiment</th>\n",
       "      <th>positive</th>\n",
       "      <th>negative</th>\n",
       "      <th>joy</th>\n",
       "      <th>sadness</th>\n",
       "      <th>anger</th>\n",
       "      <th>fear</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GEM</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>General</td>\n",
       "      <td>51.17</td>\n",
       "      <td>48.83</td>\n",
       "      <td>41.63</td>\n",
       "      <td>26.41</td>\n",
       "      <td>3.66</td>\n",
       "      <td>28.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GEM</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>Negative</td>\n",
       "      <td>2.35</td>\n",
       "      <td>97.65</td>\n",
       "      <td>2.09</td>\n",
       "      <td>49.36</td>\n",
       "      <td>10.79</td>\n",
       "      <td>37.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GEM</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>Positive</td>\n",
       "      <td>57.06</td>\n",
       "      <td>42.94</td>\n",
       "      <td>57.46</td>\n",
       "      <td>22.84</td>\n",
       "      <td>17.13</td>\n",
       "      <td>2.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GEM</td>\n",
       "      <td>User Group Aware</td>\n",
       "      <td>General</td>\n",
       "      <td>62.05</td>\n",
       "      <td>37.95</td>\n",
       "      <td>53.09</td>\n",
       "      <td>25.49</td>\n",
       "      <td>1.61</td>\n",
       "      <td>19.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GEM</td>\n",
       "      <td>User Group Aware</td>\n",
       "      <td>Negative</td>\n",
       "      <td>7.39</td>\n",
       "      <td>92.61</td>\n",
       "      <td>15.60</td>\n",
       "      <td>66.99</td>\n",
       "      <td>7.05</td>\n",
       "      <td>10.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GEM</td>\n",
       "      <td>User Group Aware</td>\n",
       "      <td>Positive</td>\n",
       "      <td>48.91</td>\n",
       "      <td>51.09</td>\n",
       "      <td>58.73</td>\n",
       "      <td>18.52</td>\n",
       "      <td>20.98</td>\n",
       "      <td>1.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GEM</td>\n",
       "      <td>User Need Aware</td>\n",
       "      <td>General</td>\n",
       "      <td>61.83</td>\n",
       "      <td>38.17</td>\n",
       "      <td>55.58</td>\n",
       "      <td>25.18</td>\n",
       "      <td>0.75</td>\n",
       "      <td>18.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>GEM</td>\n",
       "      <td>User Need Aware</td>\n",
       "      <td>Negative</td>\n",
       "      <td>25.51</td>\n",
       "      <td>74.49</td>\n",
       "      <td>26.54</td>\n",
       "      <td>56.74</td>\n",
       "      <td>4.79</td>\n",
       "      <td>11.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GEM</td>\n",
       "      <td>User Need Aware</td>\n",
       "      <td>Positive</td>\n",
       "      <td>50.46</td>\n",
       "      <td>49.54</td>\n",
       "      <td>51.52</td>\n",
       "      <td>21.68</td>\n",
       "      <td>23.22</td>\n",
       "      <td>3.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GPT</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>General</td>\n",
       "      <td>41.22</td>\n",
       "      <td>58.78</td>\n",
       "      <td>27.09</td>\n",
       "      <td>22.63</td>\n",
       "      <td>1.34</td>\n",
       "      <td>48.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GPT</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.04</td>\n",
       "      <td>99.96</td>\n",
       "      <td>0.16</td>\n",
       "      <td>46.98</td>\n",
       "      <td>5.55</td>\n",
       "      <td>47.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GPT</td>\n",
       "      <td>Baseline</td>\n",
       "      <td>Positive</td>\n",
       "      <td>53.89</td>\n",
       "      <td>46.11</td>\n",
       "      <td>37.67</td>\n",
       "      <td>42.61</td>\n",
       "      <td>8.41</td>\n",
       "      <td>11.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>GPT</td>\n",
       "      <td>User Group Aware</td>\n",
       "      <td>General</td>\n",
       "      <td>62.09</td>\n",
       "      <td>37.91</td>\n",
       "      <td>58.24</td>\n",
       "      <td>18.12</td>\n",
       "      <td>0.33</td>\n",
       "      <td>23.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>GPT</td>\n",
       "      <td>User Group Aware</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.03</td>\n",
       "      <td>99.97</td>\n",
       "      <td>2.45</td>\n",
       "      <td>62.59</td>\n",
       "      <td>3.33</td>\n",
       "      <td>31.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GPT</td>\n",
       "      <td>User Group Aware</td>\n",
       "      <td>Positive</td>\n",
       "      <td>79.72</td>\n",
       "      <td>20.28</td>\n",
       "      <td>64.80</td>\n",
       "      <td>18.44</td>\n",
       "      <td>12.32</td>\n",
       "      <td>4.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>GPT</td>\n",
       "      <td>User Need Aware</td>\n",
       "      <td>General</td>\n",
       "      <td>98.50</td>\n",
       "      <td>1.50</td>\n",
       "      <td>9.50</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.05</td>\n",
       "      <td>90.27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    IAS       Prompt Type Task Sentiment  positive  negative    joy  sadness  \\\n",
       "0   GEM          Baseline        General     51.17     48.83  41.63    26.41   \n",
       "1   GEM          Baseline       Negative      2.35     97.65   2.09    49.36   \n",
       "2   GEM          Baseline       Positive     57.06     42.94  57.46    22.84   \n",
       "3   GEM  User Group Aware        General     62.05     37.95  53.09    25.49   \n",
       "4   GEM  User Group Aware       Negative      7.39     92.61  15.60    66.99   \n",
       "5   GEM  User Group Aware       Positive     48.91     51.09  58.73    18.52   \n",
       "6   GEM   User Need Aware        General     61.83     38.17  55.58    25.18   \n",
       "7   GEM   User Need Aware       Negative     25.51     74.49  26.54    56.74   \n",
       "8   GEM   User Need Aware       Positive     50.46     49.54  51.52    21.68   \n",
       "9   GPT          Baseline        General     41.22     58.78  27.09    22.63   \n",
       "10  GPT          Baseline       Negative      0.04     99.96   0.16    46.98   \n",
       "11  GPT          Baseline       Positive     53.89     46.11  37.67    42.61   \n",
       "12  GPT  User Group Aware        General     62.09     37.91  58.24    18.12   \n",
       "13  GPT  User Group Aware       Negative      0.03     99.97   2.45    62.59   \n",
       "14  GPT  User Group Aware       Positive     79.72     20.28  64.80    18.44   \n",
       "15  GPT   User Need Aware        General     98.50      1.50   9.50     0.18   \n",
       "\n",
       "    anger   fear  \n",
       "0    3.66  28.30  \n",
       "1   10.79  37.75  \n",
       "2   17.13   2.58  \n",
       "3    1.61  19.81  \n",
       "4    7.05  10.36  \n",
       "5   20.98   1.78  \n",
       "6    0.75  18.50  \n",
       "7    4.79  11.93  \n",
       "8   23.22   3.58  \n",
       "9    1.34  48.94  \n",
       "10   5.55  47.31  \n",
       "11   8.41  11.31  \n",
       "12   0.33  23.31  \n",
       "13   3.33  31.63  \n",
       "14  12.32   4.44  \n",
       "15   0.05  90.27  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os  # import os module\n",
    "\n",
    "directory = '../Results/'  # set directory path\n",
    "\n",
    "all_EP_list = []\n",
    "for entry in os.scandir(directory):  \n",
    "    if entry.is_file():  # check if it's a file\n",
    "        results_df = pd.read_csv(entry.path)\n",
    "        file_name = entry.name[10:-4]\n",
    "        EP_vals = results_df.groupby(\"Task Sentiment\").mean(numeric_only=True).round(2).reset_index()\n",
    "        if \"gemma\" in file_name: \n",
    "            EP_vals[\"IAS\"] = [\"GEM\"]*len(EP_vals)\n",
    "        elif \"gpt\" in file_name:\n",
    "            EP_vals[\"IAS\"] = [\"GPT\"]*len(EP_vals)\n",
    "\n",
    "        if \"baseline\" in file_name:\n",
    "            EP_vals[\"Prompt Type\"] = [\"Baseline\"]*len(EP_vals)\n",
    "        elif \"user_group_aware\" in file_name:\n",
    "            EP_vals[\"Prompt Type\"] = [\"User Group Aware\"]*len(EP_vals)\n",
    "        elif \"user_need_aware\" in file_name:\n",
    "            EP_vals[\"Prompt Type\"] = [\"User Need Aware\"] * len(EP_vals)\n",
    "\n",
    "        EP_vals = EP_vals.loc[:, [\"IAS\", \"Prompt Type\", \"Task Sentiment\", \"positive\", \"negative\", \"joy\", \"sadness\", \"anger\", \"fear\"]]\n",
    "        all_EP_list.append(EP_vals)\n",
    "\n",
    "all_EP_df = pd.concat(all_EP_list, ignore_index=True)\n",
    "all_EP_df.to_csv(\"../Results/EP.csv\", index=False)\n",
    "all_EP_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SOLandChildren",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
